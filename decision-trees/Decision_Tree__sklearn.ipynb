{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with entropy, information gain, and decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris fact of the day: Iris setosa's root contains a toxin that was used by the Aleut tribe in Alaska to make poisonous arrowheads.\n",
    "\n",
    "This is a version of the notebook where we just focus on the sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For producing decision tree diagrams.\n",
    "from IPython.core.display import Image, display\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "# Split into train and test.\n",
    "train_data, train_labels = X[:100], Y[:100]\n",
    "test_data, test_labels = X[100:], Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following questions, you'll might find this function useful to print out the tree. If you want to try a graphical way, look into this function:\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "\n",
    "The below function prints out a 'pseudocode' version of the tree, in terms of if-else statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_code(tree, feature_names):\n",
    "        left      = tree.tree_.children_left\n",
    "        right     = tree.tree_.children_right\n",
    "        threshold = tree.tree_.threshold\n",
    "        features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "        value = tree.tree_.value\n",
    "\n",
    "        def recurse(left, right, threshold, features, node):\n",
    "                if (threshold[node] != -2):\n",
    "                        print \"if ( \" + features[node] + \" <= \" + str(threshold[node]) + \" ) {\"\n",
    "                        if left[node] != -1:\n",
    "                                recurse (left, right, threshold, features,left[node])\n",
    "                        print \"} else {\"\n",
    "                        if right[node] != -1:\n",
    "                                recurse (left, right, threshold, features,right[node])\n",
    "                        print \"}\"\n",
    "                else:\n",
    "                        print \"return \" + str(value[node])\n",
    "\n",
    "        recurse(left, right, threshold, features, 0)\n",
    "\n",
    "# example call:\n",
    "# get_code(dt, iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what the DecisionTreeClassifier from sklearn can do. Be sure to reference the documentation at:  http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Here is the basic code to fit a deision tree, and evaluate its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "if ( petal width (cm) <= 0.800000011921 ) {\n",
      "return [[ 31.   0.   0.]]\n",
      "} else {\n",
      "if ( petal width (cm) <= 1.65000009537 ) {\n",
      "if ( petal length (cm) <= 4.94999980927 ) {\n",
      "return [[  0.  32.   0.]]\n",
      "} else {\n",
      "if ( sepal length (cm) <= 6.05000019073 ) {\n",
      "if ( petal length (cm) <= 5.05000019073 ) {\n",
      "return [[ 0.  0.  1.]]\n",
      "} else {\n",
      "return [[ 0.  1.  0.]]\n",
      "}\n",
      "} else {\n",
      "return [[ 0.  0.  3.]]\n",
      "}\n",
      "}\n",
      "} else {\n",
      "return [[  0.   0.  32.]]\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print 'Accuracy:', dt.score(test_data, test_labels)\n",
    "\n",
    "get_code(dt, iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some things to try:\n",
    "\n",
    "1. For the above basic tree, what features did it use in what order? where did it split the features? What is the tree's depth?\n",
    "2. Try changing the split criterion to 'entropy', does that make any impact in accuracy? In what features are used? In where you split the features?\n",
    "3. Try making a decision tree of depth 1, how does its performance compare to the basic one? On what feature does it split? \n",
    "4. Look at the sklearn documentation, and look into the other parameters. Try one out, what does it do? If it is a numeric parameter, try some extreme cases, what happens?\n",
    "5. Try adding some additional random features to the feature set. Does the tree ignore them? How could you prevent overfitting?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
